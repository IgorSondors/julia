2022-12-12 16:28:25.723949: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2022-12-12 16:28:26.856290: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2022-12-12 16:28:26.857219: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1
2022-12-12 16:28:27.009985: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:8b:00.0 name: Tesla T4 computeCapability: 7.5
coreClock: 1.59GHz coreCount: 40 deviceMemorySize: 14.56GiB deviceMemoryBandwidth: 298.08GiB/s
2022-12-12 16:28:27.010043: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2022-12-12 16:28:27.012046: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2022-12-12 16:28:27.012127: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2022-12-12 16:28:27.013802: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2022-12-12 16:28:27.014130: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2022-12-12 16:28:27.016052: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2022-12-12 16:28:27.017006: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2022-12-12 16:28:27.020977: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2022-12-12 16:28:27.025990: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2022-12-12 16:28:27.058791: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2022-12-12 16:28:27.061183: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2022-12-12 16:28:27.063889: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:8b:00.0 name: Tesla T4 computeCapability: 7.5
coreClock: 1.59GHz coreCount: 40 deviceMemorySize: 14.56GiB deviceMemoryBandwidth: 298.08GiB/s
2022-12-12 16:28:27.063930: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2022-12-12 16:28:27.063976: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2022-12-12 16:28:27.063988: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2022-12-12 16:28:27.063998: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2022-12-12 16:28:27.064009: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2022-12-12 16:28:27.064018: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2022-12-12 16:28:27.064028: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2022-12-12 16:28:27.064039: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2022-12-12 16:28:27.068873: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2022-12-12 16:28:27.068934: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2022-12-12 16:28:27.692432: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2022-12-12 16:28:27.692480: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 
2022-12-12 16:28:27.692488: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N 
2022-12-12 16:28:27.698958: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 13784 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:8b:00.0, compute capability: 7.5)
np.shape(wn) =  (None, 128, 128, 3)
np.shape(dct) =  (None, 128, 128, 3)
np.shape(wn) =  (None, 128, 128, 3)
np.shape(fft) =  (None, 128, 128, 6)
Model: "model_2"
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            [(None, 128, 128, 3) 0                                            
__________________________________________________________________________________________________
regular_normfft3d (Lambda)      (None, 128, 128, 3)  0           input_1[0][0]                    
__________________________________________________________________________________________________
fft (Lambda)                    ((None, 128, 128, 3) 0           regular_normfft3d[0][0]          
__________________________________________________________________________________________________
regular_normdct (Lambda)        (None, 128, 128, 3)  0           input_1[0][0]                    
__________________________________________________________________________________________________
tf.cast (TFOpLambda)            (None, 128, 128, 3)  0           fft[0][0]                        
__________________________________________________________________________________________________
tf.cast_1 (TFOpLambda)          (None, 128, 128, 3)  0           fft[0][1]                        
__________________________________________________________________________________________________
dct (Lambda)                    (None, 128, 128, 3)  0           regular_normdct[0][0]            
__________________________________________________________________________________________________
tf.concat (TFOpLambda)          (None, 128, 128, 6)  0           tf.cast[0][0]                    
                                                                 tf.cast_1[0][0]                  
__________________________________________________________________________________________________
conv2d (Conv2D)                 (None, 126, 126, 32) 864         dct[0][0]                        
__________________________________________________________________________________________________
conv2d_1 (Conv2D)               (None, 126, 126, 32) 1728        tf.concat[0][0]                  
__________________________________________________________________________________________________
batch_normalization (BatchNorma (None, 126, 126, 32) 128         conv2d[0][0]                     
__________________________________________________________________________________________________
batch_normalization_4 (BatchNor (None, 126, 126, 32) 128         conv2d_1[0][0]                   
__________________________________________________________________________________________________
activation (Activation)         (None, 126, 126, 32) 0           batch_normalization[0][0]        
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 126, 126, 32) 0           batch_normalization_4[0][0]      
__________________________________________________________________________________________________
average_pooling2d (AveragePooli (None, 63, 63, 32)   0           activation[0][0]                 
__________________________________________________________________________________________________
average_pooling2d_3 (AveragePoo (None, 63, 63, 32)   0           activation_4[0][0]               
__________________________________________________________________________________________________
global_average_pooling2d (Globa (None, 32)           0           average_pooling2d[0][0]          
__________________________________________________________________________________________________
global_average_pooling2d_5 (Glo (None, 32)           0           average_pooling2d_3[0][0]        
__________________________________________________________________________________________________
dense (Dense)                   (None, 16)           528         global_average_pooling2d[0][0]   
__________________________________________________________________________________________________
dense_11 (Dense)                (None, 16)           528         global_average_pooling2d_5[0][0] 
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 32)           544         dense[0][0]                      
__________________________________________________________________________________________________
dense_12 (Dense)                (None, 32)           544         dense_11[0][0]                   
__________________________________________________________________________________________________
multiply (Multiply)             (None, 63, 63, 32)   0           dense_1[0][0]                    
                                                                 average_pooling2d[0][0]          
__________________________________________________________________________________________________
multiply_5 (Multiply)           (None, 63, 63, 32)   0           dense_12[0][0]                   
                                                                 average_pooling2d_3[0][0]        
__________________________________________________________________________________________________
conv2_dct (Conv2D)              (None, 61, 61, 32)   9248        multiply[0][0]                   
__________________________________________________________________________________________________
conv2_fft3d (Conv2D)            (None, 61, 61, 32)   9248        multiply_5[0][0]                 
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 61, 61, 32)   128         conv2_dct[0][0]                  
__________________________________________________________________________________________________
batch_normalization_5 (BatchNor (None, 61, 61, 32)   128         conv2_fft3d[0][0]                
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 61, 61, 32)   0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 61, 61, 32)   0           batch_normalization_5[0][0]      
__________________________________________________________________________________________________
average_pooling2d_1 (AveragePoo (None, 30, 30, 32)   0           activation_1[0][0]               
__________________________________________________________________________________________________
average_pooling2d_4 (AveragePoo (None, 30, 30, 32)   0           activation_5[0][0]               
__________________________________________________________________________________________________
global_average_pooling2d_1 (Glo (None, 32)           0           average_pooling2d_1[0][0]        
__________________________________________________________________________________________________
global_average_pooling2d_6 (Glo (None, 32)           0           average_pooling2d_4[0][0]        
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 16)           528         global_average_pooling2d_1[0][0] 
__________________________________________________________________________________________________
dense_13 (Dense)                (None, 16)           528         global_average_pooling2d_6[0][0] 
__________________________________________________________________________________________________
dense_3 (Dense)                 (None, 32)           544         dense_2[0][0]                    
__________________________________________________________________________________________________
dense_14 (Dense)                (None, 32)           544         dense_13[0][0]                   
__________________________________________________________________________________________________
multiply_1 (Multiply)           (None, 30, 30, 32)   0           dense_3[0][0]                    
                                                                 average_pooling2d_1[0][0]        
__________________________________________________________________________________________________
multiply_6 (Multiply)           (None, 30, 30, 32)   0           dense_14[0][0]                   
                                                                 average_pooling2d_4[0][0]        
__________________________________________________________________________________________________
conv3_dct (Conv2D)              (None, 28, 28, 32)   9248        multiply_1[0][0]                 
__________________________________________________________________________________________________
conv3_fft3d (Conv2D)            (None, 28, 28, 32)   9248        multiply_6[0][0]                 
__________________________________________________________________________________________________
batch_normalization_2 (BatchNor (None, 28, 28, 32)   128         conv3_dct[0][0]                  
__________________________________________________________________________________________________
batch_normalization_6 (BatchNor (None, 28, 28, 32)   128         conv3_fft3d[0][0]                
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 28, 28, 32)   0           batch_normalization_2[0][0]      
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 28, 28, 32)   0           batch_normalization_6[0][0]      
__________________________________________________________________________________________________
average_pooling2d_2 (AveragePoo (None, 14, 14, 32)   0           activation_2[0][0]               
__________________________________________________________________________________________________
average_pooling2d_5 (AveragePoo (None, 14, 14, 32)   0           activation_6[0][0]               
__________________________________________________________________________________________________
global_average_pooling2d_2 (Glo (None, 32)           0           average_pooling2d_2[0][0]        
__________________________________________________________________________________________________
global_average_pooling2d_7 (Glo (None, 32)           0           average_pooling2d_5[0][0]        
__________________________________________________________________________________________________
dense_4 (Dense)                 (None, 16)           528         global_average_pooling2d_2[0][0] 
__________________________________________________________________________________________________
dense_15 (Dense)                (None, 16)           528         global_average_pooling2d_7[0][0] 
__________________________________________________________________________________________________
dense_5 (Dense)                 (None, 32)           544         dense_4[0][0]                    
__________________________________________________________________________________________________
dense_16 (Dense)                (None, 32)           544         dense_15[0][0]                   
__________________________________________________________________________________________________
multiply_2 (Multiply)           (None, 14, 14, 32)   0           dense_5[0][0]                    
                                                                 average_pooling2d_2[0][0]        
__________________________________________________________________________________________________
multiply_7 (Multiply)           (None, 14, 14, 32)   0           dense_16[0][0]                   
                                                                 average_pooling2d_5[0][0]        
__________________________________________________________________________________________________
conv4_dct (Conv2D)              (None, 12, 12, 32)   9216        multiply_2[0][0]                 
__________________________________________________________________________________________________
conv4_fft3d (Conv2D)            (None, 12, 12, 32)   9216        multiply_7[0][0]                 
__________________________________________________________________________________________________
batch_normalization_3 (BatchNor (None, 12, 12, 32)   128         conv4_dct[0][0]                  
__________________________________________________________________________________________________
batch_normalization_7 (BatchNor (None, 12, 12, 32)   128         conv4_fft3d[0][0]                
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 12, 12, 32)   0           batch_normalization_3[0][0]      
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 12, 12, 32)   0           batch_normalization_7[0][0]      
__________________________________________________________________________________________________
global_average_pooling2d_3 (Glo (None, 32)           0           activation_3[0][0]               
__________________________________________________________________________________________________
global_average_pooling2d_8 (Glo (None, 32)           0           activation_7[0][0]               
__________________________________________________________________________________________________
dense_6 (Dense)                 (None, 16)           528         global_average_pooling2d_3[0][0] 
__________________________________________________________________________________________________
dense_17 (Dense)                (None, 16)           528         global_average_pooling2d_8[0][0] 
__________________________________________________________________________________________________
dense_7 (Dense)                 (None, 32)           544         dense_6[0][0]                    
__________________________________________________________________________________________________
dense_18 (Dense)                (None, 32)           544         dense_17[0][0]                   
__________________________________________________________________________________________________
multiply_3 (Multiply)           (None, 12, 12, 32)   0           dense_7[0][0]                    
                                                                 activation_3[0][0]               
__________________________________________________________________________________________________
multiply_8 (Multiply)           (None, 12, 12, 32)   0           dense_18[0][0]                   
                                                                 activation_7[0][0]               
__________________________________________________________________________________________________
conv5_dct (Conv2D)              (None, 12, 12, 32)   1056        multiply_3[0][0]                 
__________________________________________________________________________________________________
conv5_fft3d (Conv2D)            (None, 12, 12, 32)   1056        multiply_8[0][0]                 
__________________________________________________________________________________________________
global_average_pooling2d_4 (Glo (None, 32)           0           conv5_dct[0][0]                  
__________________________________________________________________________________________________
global_average_pooling2d_9 (Glo (None, 32)           0           conv5_fft3d[0][0]                
__________________________________________________________________________________________________
dense_8 (Dense)                 (None, 16)           528         global_average_pooling2d_4[0][0] 
__________________________________________________________________________________________________
dense_19 (Dense)                (None, 16)           528         global_average_pooling2d_9[0][0] 
WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.
2022-12-12 16:29:08.689279: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)
2022-12-12 16:29:08.689681: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 1995310000 Hz
2022-12-12 16:29:12.423260: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2022-12-12 16:29:13.459181: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2022-12-12 16:29:13.740659: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2022-12-12 16:29:14.876134: W tensorflow/stream_executor/gpu/asm_compiler.cc:63] Running ptxas --version returned 256
2022-12-12 16:29:15.038213: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] Internal: ptxas exited with non-zero error code 256, output: 
Relying on driver to perform ptx compilation. 
Modify $PATH to customize ptxas location.
This message will be only logged once.
__________________________________________________________________________________________________
dense_9 (Dense)                 (None, 32)           544         dense_8[0][0]                    
__________________________________________________________________________________________________
dense_20 (Dense)                (None, 32)           544         dense_19[0][0]                   
__________________________________________________________________________________________________
multiply_4 (Multiply)           (None, 12, 12, 32)   0           dense_9[0][0]                    
                                                                 conv5_dct[0][0]                  
__________________________________________________________________________________________________
multiply_9 (Multiply)           (None, 12, 12, 32)   0           dense_20[0][0]                   
                                                                 conv5_fft3d[0][0]                
__________________________________________________________________________________________________
flatten (Flatten)               (None, 4608)         0           multiply_4[0][0]                 
__________________________________________________________________________________________________
flatten_1 (Flatten)             (None, 4608)         0           multiply_9[0][0]                 
__________________________________________________________________________________________________
dropout (Dropout)               (None, 4608)         0           flatten[0][0]                    
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 4608)         0           flatten_1[0][0]                  
__________________________________________________________________________________________________
dense_10 (Dense)                (None, 32)           147488      dropout[0][0]                    
__________________________________________________________________________________________________
dense_21 (Dense)                (None, 32)           147488      dropout_1[0][0]                  
__________________________________________________________________________________________________
concatenate (Concatenate)       (None, 64)           0           dense_10[0][0]                   
                                                                 dense_21[0][0]                   
__________________________________________________________________________________________________
dense_22 (Dense)                (None, 12)           780         concatenate[0][0]                
__________________________________________________________________________________________________
dense_23 (Dense)                (None, 1)            13          dense_22[0][0]                   
==================================================================================================
Total params: 367,641
Trainable params: 367,129
Non-trainable params: 512
__________________________________________________________________________________________________
None
                                                    file spoof
0      /mnt/data/lossless_val_04102022_crops/1/chrome...     1
1      /mnt/data/lossless_val_04102022_crops/1/2d7db3...     1
2      /mnt/data/lossless_val_04102022_crops/1/chroma...     1
3      /mnt/data/lossless_val_04102022_crops/0/c86649...     0
4      /mnt/data/lossless_val_04102022_crops/1/chrome...     1
...                                                  ...   ...
40073  /mnt/data/lossless_val_04102022_crops/1/chrome...     1
40074  /mnt/data/lossless_val_04102022_crops/0/5c2b86...     0
40075  /mnt/data/lossless_val_04102022_crops/0/5c79a2...     0
40076  /mnt/data/lossless_val_04102022_crops/1/firefo...     1
40077  /mnt/data/lossless_val_04102022_crops/1/63559a...     1

[40078 rows x 2 columns]
train_cls_n =  [2785410, 2859310] 2
test_cls_n =  [19998, 20080] 2
Found 5644720 validated image filenames belonging to 2 classes.
Found 40078 validated image filenames belonging to 2 classes.
Epoch 1/7
    1/11289 [..............................] - ETA: 125:54:11 - loss: 0.6946 - accuracy: 0.5120    2/11289 [..............................] - ETA: 2:32:58 - loss: 0.6980 - accuracy: 0.5150      3/11289 [..............................] - ETA: 2:25:47 - loss: 0.7129 - accuracy: 0.5202    4/11289 [..............................] - ETA: 2:23:31 - loss: 0.7158 - accuracy: 0.5278    5/11289 [..............................] - ETA: 2:22:29 - loss: 0.7144 - accuracy: 0.5350    6/11289 [..............................] - ETA: 2:22:02 - loss: 0.7115 - accuracy: 0.5417    7/11289 [..............................] - ETA: 2:21:19 - loss: 0.7076 - accuracy: 0.5483    8/11289 [..............................] - ETA: 2:20:44 - loss: 0.7037 - accuracy: 0.5544    9/11289 [..............................] - ETA: 2:20:26 - loss: 0.7003 - accuracy: 0.5589   10/11289 [..............................] - ETA: 2:20:11 - loss: 0.6969 - accuracy: 0.5637   11/11289 [..............................] - ETA: 2:20:04 - loss: 0.6933 - accuracy: 0.5686   12/11289 [..............................] - ETA: 2:19:52 - loss: 0.6896 - accuracy: 0.5734   13/11289 [..............................] - ETA: 2:19:44 - loss: 0.6863 - accuracy: 0.5780   14/11289 [..............................] - ETA: 2:19:35 - loss: 0.6830 - accuracy: 0.5824   15/11289 [..............................] - ETA: 2:19:26 - loss: 0.6798 - accuracy: 0.5866   16/11289 [..............................] - ETA: 2:19:22 - loss: 0.6766 - accuracy: 0.5907   17/11289 [..............................] - ETA: 2:19:19 - loss: 0.6736 - accuracy: 0.5945   18/11289 [..............................] - ETA: 2:19:15 - loss: 0.6708 - accuracy: 0.5980   19/11289 [..............................] - ETA: 2:19:19 - loss: 0.6681 - accuracy: 0.6014   20/11289 [..............................] - ETA: 2:19:16 - loss: 0.6656 - accuracy: 0.6047   21/11289 [..............................] - ETA: 2:19:13 - loss: 0.6632 - accuracy: 0.6078   22/11289 [..............................] - ETA: 2:19:13 - loss: 0.6608 - accuracy: 0.6107   23/11289 [..............................] - ETA: 2:19:08 - loss: 0.6585 - accuracy: 0.6135   24/11289 [..............................] - ETA: 2:19:06 - loss: 0.6563 - accuracy: 0.6162   25/11289 [..............................] - ETA: 2:19:03 - loss: 0.6542 - accuracy: 0.6187   26/11289 [..............................] - ETA: 2:19:00 - loss: 0.6522 - accuracy: 0.6212   27/11289 [..............................] - ETA: 2:19:17 - loss: 0.6504 - accuracy: 0.6235   28/11289 [..............................] - ETA: 2:19:14 - loss: 0.6485 - accuracy: 0.6257   29/11289 [..............................] - ETA: 2:19:11 - loss: 0.6466 - accuracy: 0.6279   30/11289 [..............................] - ETA: 2:19:08 - loss: 0.6448 - accuracy: 0.6300   31/11289 [..............................] - ETA: 2:19:06 - loss: 0.6431 - accuracy: 0.6319   32/11289 [..............................] - ETA: 2:19:04 - loss: 0.6414 - accuracy: 0.6338   33/11289 [..............................] - ETA: 2:18:59 - loss: 0.6398 - accuracy: 0.6356   34/11289 [..............................] - ETA: 2:18:58 - loss: 0.6383 - accuracy: 0.6374   35/11289 [..............................] - ETA: 2:18:58 - loss: 0.6367 - accuracy: 0.6391   36/11289 [..............................] - ETA: 2:18:55 - loss: 0.6352 - accuracy: 0.6407   37/11289 [..............................] - ETA: 2:18:52 - loss: 0.6338 - accuracy: 0.6423   38/11289 [..............................] - ETA: 2:18:50 - loss: 0.6323 - accuracy: 0.6439   39/11289 [..............................] - ETA: 2:18:49 - loss: 0.6309 - accuracy: 0.6455   40/11289 [..............................] - ETA: 2:18:48 - loss: 0.6295 - accuracy: 0.6470   41/11289 [..............................] - ETA: 2:18:45 - loss: 0.6282 - accuracy: 0.6484   42/11289 [..............................] - ETA: 2:18:45 - loss: 0.6268 - accuracy: 0.6498   43/11289 [..............................] - ETA: 2:18:44 - loss: 0.6255 - accuracy: 0.6512   44/11289 [..............................] - ETA: 2:18:42 - loss: 0.6242 - accuracy: 0.6526   45/11289 [..............................] - ETA: 2:18:42 - loss: 0.6229 - accuracy: 0.6539   46/11289 [..............................] - ETA: 2:18:41 - loss: 0.6217 - accuracy: 0.6552   47/11289 [..............................] - ETA: 2:18:41 - loss: 0.6204 - accuracy: 0.6565   48/11289 [..............................] - ETA: 2:18:46 - loss: 0.6191 - accuracy: 0.6578   49/11289 [..............................] - ETA: 2:18:45 - loss: 0.6179 - accuracy: 0.6590   50/11289 [..............................] - ETA: 2:18:45 - loss: 0.6167 - accuracy: 0.6602   51/11289 [..............................] - ETA: 2:18:44 - loss: 0.6155 - accuracy: 0.6614   52/11289 [..............................] - ETA: 2:18:44 - loss: 0.6143 - accuracy: 0.6625   53/11289 [..............................] - ETA: 2:18:43 - loss: 0.6132 - accuracy: 0.6636   54/11289 [..............................] - ETA: 2:18:42 - loss: 0.6120 - accuracy: 0.6648   55/11289 [..............................] - ETA: 2:18:41 - loss: 0.6109 - accuracy: 0.6659   56/11289 [..............................] - ETA: 2:18:49 - loss: 0.6098 - accuracy: 0.6669   57/11289 [..............................] - ETA: 2:18:48 - loss: 0.6086 - accuracy: 0.6680   58/11289 [..............................] - ETA: 2:18:46 - loss: 0.6075 - accuracy: 0.6690   59/11289 [..............................] - ETA: 2:18:45 - loss: 0.6064 - accuracy: 0.6701   60/11289 [..............................] - ETA: 2:18:44 - loss: 0.6053 - accuracy: 0.6711   61/11289 [..............................] - ETA: 2:18:42 - loss: 0.6043 - accuracy: 0.6721   62/11289 [..............................] - ETA: 2:18:41 - loss: 0.6032 - accuracy: 0.6731   63/11289 [..............................] - ETA: 2:18:40 - loss: 0.6022 - accuracy: 0.6740   64/11289 [..............................] - ETA: 2:18:37 - loss: 0.6011 - accuracy: 0.6750   65/11289 [..............................] - ETA: 2:18:36 - loss: 0.6001 - accuracy: 0.6759   66/11289 [..............................] - ETA: 2:18:36 - loss: 0.5990 - accuracy: 0.6769   67/11289 [..............................] - ETA: 2:18:35 - loss: 0.5980 - accuracy: 0.6778   68/11289 [..............................] - ETA: 2:18:33 - loss: 0.5970 - accuracy: 0.6787   69/11289 [..............................] - ETA: 2:18:34 - loss: 0.5960 - accuracy: 0.6796   70/11289 [..............................] - ETA: 2:18:33 - loss: 0.5950 - accuracy: 0.6805   71/11289 [..............................] - ETA: 2:18:31 - loss: 0.5940 - accuracy: 0.6814   72/11289 [..............................] - ETA: 2:18:30 - loss: 0.5931 - accuracy: 0.6822   73/11289 [..............................] - ETA: 2:18:28 - loss: 0.5921 - accuracy: 0.6830   74/11289 [..............................] - ETA: 2:18:26 - loss: 0.5912 - accuracy: 0.6839   75/11289 [..............................] - ETA: 2:18:26 - loss: 0.5903 - accuracy: 0.6847   76/11289 [..............................] - ETA: 2:18:24 - loss: 0.5894 - accuracy: 0.6855   77/11289 [..............................] - ETA: 2:18:28 - loss: 0.5885 - accuracy: 0.6863   78/11289 [..............................] - ETA: 2:18:27 - loss: 0.5876 - accuracy: 0.6870   79/11289 [..............................] - ETA: 2:18:26 - loss: 0.5867 - accuracy: 0.6878   80/11289 [..............................] - ETA: 2:18:25 - loss: 0.5858 - accuracy: 0.6886   81/11289 [..............................] - ETA: 2:18:24 - loss: 0.5849 - accuracy: 0.6893   82/11289 [..............................] - ETA: 2:18:22 - loss: 0.5841 - accuracy: 0.6901   83/11289 [..............................] - ETA: 2:18:22 - loss: 0.5832 - accuracy: 0.6908   84/11289 [..............................] - ETA: 2:18:21 - loss: 0.5823 - accuracy: 0.6916   85/11289 [..............................] - ETA: 2:18:21 - loss: 0.5815 - accuracy: 0.6923   86/11289 [..............................] - ETA: 2:18:20 - loss: 0.5806 - accuracy: 0.6930   87/11289 [..............................] - ETA: 2:18:19 - loss: 0.5798 - accuracy: 0.6937   88/11289 [..............................] - ETA: 2:18:18 - loss: 0.5790 - accuracy: 0.6944   89/11289 [..............................] - ETA: 2:18:17 - loss: 0.5782 - accuracy: 0.6951   90/11289 [..............................] - ETA: 2:18:16 - loss: 0.5774 - accuracy: 0.6958   91/11289 [..............................] - ETA: 2:18:15 - loss: 0.5766 - accuracy: 0.6965   92/11289 [..............................] - ETA: 2:18:14 - loss: 0.5758 - accuracy: 0.6971   93/11289 [..............................] - ETA: 2:18:13 - loss: 0.5750 - accuracy: 0.6978   94/11289 [..............................] - ETA: 2:18:11 - loss: 0.5743 - accuracy: 0.6984   95/11289 [..............................] - ETA: 2:18:10 - loss: 0.5735 - accuracy: 0.6991   96/11289 [..............................] - ETA: 2:18:08 - loss: 0.5728 - accuracy: 0.6997   97/11289 [..............................] - ETA: 2:18:07 - loss: 0.5720 - accuracy: 0.7003   98/11289 [..............................] - ETA: 2:18:11 - loss: 0.5713 - accuracy: 0.7010   99/11289 [..............................] - ETA: 2:18:10 - loss: 0.5705 - accuracy: 0.7016  100/11289 [..............................] - ETA: 2:18:09 - loss: 0.5698 - accuracy: 0.7022  101/11289 [..............................] - ETA: 2:18:08 - loss: 0.5691 - accuracy: 0.7028  102/11289 [..............................] - ETA: 2:18:07 - loss: 0.5684 - accuracy: 0.7034  103/11289 [..............................] - ETA: 2:18:06 - loss: 0.5677 - accuracy: 0.7040  104/11289 [..............................] - ETA: 2:18:06 - loss: 0.5670 - accuracy: 0.7045  105/11289 [..............................] - ETA: 2:18:05 - loss: 0.5663 - accuracy: 0.7051  106/11289 [..............................] - ETA: 2:18:08 - loss: 0.5656 - accuracy: 0.7057  107/11289 [..............................] - ETA: 2:18:08 - loss: 0.5649 - accuracy: 0.7063  108/11289 [..............................] - ETA: 2:18:07 - loss: 0.5642 - accuracy: 0.7068  109/11289 [..............................] - ETA: 2:18:07 - loss: 0.5635 - accuracy: 0.7074  110/11289 [..............................] - ETA: 2:18:06 - loss: 0.5629 - accuracy: 0.7079  111/11289 [..............................] - ETA: 2:18:05 - loss: 0.5622 - accuracy: 0.7085  112/11289 [..............................] - ETA: 2:18:03 - loss: 0.5616 - accuracy: 0.7090  113/11289 [..............................] - ETA: 2:18:02 - loss: 0.5609 - accuracy: 0.7095  114/11289 [..............................] - ETA: 2:18:07 - loss: 0.5603 - accuracy: 0.7101  115/11289 [..............................] - ETA: 2:18:06 - loss: 0.5596 - accuracy: 0.7106  116/11289 [..............................] - ETA: 2:18:05 - loss: 0.5590 - accuracy: 0.7111  117/11289 [..............................] - ETA: 2:18:04 - loss: 0.5583 - accuracy: 0.7116  118/11289 [..............................] - ETA: 2:18:04 - loss: 0.5577 - accuracy: 0.7121  119/11289 [..............................] - ETA: 2:18:03 - loss: 0.5571 - accuracy: 0.7126  120/11289 [..............................] - ETA: 2:18:02 - loss: 0.5564 - accuracy: 0.7131  121/11289 [..............................] - ETA: 2:18:01 - loss: 0.5558 - accuracy: 0.7136  122/11289 [..............................] - ETA: 2:18:04 - loss: 0.5552 - accuracy: 0.7141  123/11289 [..............................] - ETA: 2:18:03 - loss: 0.5546 - accuracy: 0.7146  124/11289 [..............................] - ETA: 2:18:02 - loss: 0.5540 - accuracy: 0.7151  125/11289 [..............................] - ETA: 2:18:01 - loss: 0.5534 - accuracy: 0.7156  126/11289 [..............................] - ETA: 2:18:00 - loss: 0.5528 - accuracy: 0.7161  127/11289 [..............................] - ETA: 2:17:59 - loss: 0.5522 - accuracy: 0.7166  128/11289 [..............................] - ETA: 2:17:58 - loss: 0.5516 - accuracy: 0.7170  129/11289 [..............................] - ETA: 2:17:57 - loss: 0.5510 - accuracy: 0.7175  130/11289 [..............................] - ETA: 2:17:57 - loss: 0.5504 - accuracy: 0.7180  131/11289 [..............................] - ETA: 2:17:56 - loss: 0.5498 - accuracy: 0.7184  132/11289 [..............................] - ETA: 2:17:55 - loss: 0.5492 - accuracy: 0.7189  133/11289 [..............................] - ETA: 2:17:54 - loss: 0.5487 - accuracy: 0.7193  134/11289 [..............................] - ETA: 2:17:53 - loss: 0.5481 - accuracy: 0.7198  135/11289 [..............................] - ETA: 2:17:52 - loss: 0.5475 - accuracy: 0.7202  136/11289 [..............................] - ETA: 2:17:51 - loss: 0.5470 - accuracy: 0.7207  137/11289 [..............................] - ETA: 2:17:50 - loss: 0.5464 - accuracy: 0.7211  138/11289 [..............................] - ETA: 2:17:49 - loss: 0.5458 - accuracy: 0.7216  139/11289 [..............................] - ETA: 2:17:48 - loss: 0.5453 - accuracy: 0.7220  140/11289 [..............................] - ETA: 2:17:49 - loss: 0.5447 - accuracy: 0.7224  141/11289 [..............................] - ETA: 2:17:48 - loss: 0.5442 - accuracy: 0.7228  142/11289 [..............................] - ETA: 2:17:47 - loss: 0.5437 - accuracy: 0.7233  143/11289 [..............................] - ETA: 2:17:47 - loss: 0.5431 - accuracy: 0.7237  144/11289 [..............................] - ETA: 2:17:46 - loss: 0.5426 - accuracy: 0.7241  145/11289 [..............................] - ETA: 2:17:45 - loss: 0.5421 - accuracy: 0.7245  146/11289 [..............................] - ETA: 2:17:44 - loss: 0.5415 - accuracy: 0.7249  147/11289 [..............................] - ETA: 2:17:43 - loss: 0.5410 - accuracy: 0.7253  148/11289 [..............................] - ETA: 2:17:42 - loss: 0.5405 - accuracy: 0.7257  149/11289 [..............................] - ETA: 2:17:41 - loss: 0.5399 - accuracy: 0.7261  150/11289 [..............................] - ETA: 2:17:40 - loss: 0.5394 - accuracy: 0.7265  151/11289 [..............................] - ETA: 2:17:42 - loss: 0.5389 - accuracy: 0.7269  152/11289 [..............................] - ETA: 2:17:41 - loss: 0.5384 - accuracy: 0.7273  153/11289 [..............................] - ETA: 2:17:40 - loss: 0.5379 - accuracy: 0.7277  154/11289 [..............................] - ETA: 2:17:39 - loss: 0.5374 - accuracy: 0.7281  155/11289 [..............................] - ETA: 2:17:39 - loss: 0.5368 - accuracy: 0.7285  156/11289 [..............................] - ETA: 2:17:38 - loss: 0.5363 - accuracy: 0.7289  157/11289 [..............................] - ETA: 2:17:37 - loss: 0.5358 - accuracy: 0.7293  158/11289 [..............................] - ETA: 2:17:37 - loss: 0.5353 - accuracy: 0.7297  159/11289 [..............................] - ETA: 2:17:39 - loss: 0.5349 - accuracy: 0.7300  160/11289 [..............................] - ETA: 2:17:38 - loss: 0.5344 - accuracy: 0.7304  161/11289 [..............................] - ETA: 2:17:37 - loss: 0.5339 - accuracy: 0.7308Traceback (most recent call last):
  File "train_dct.py", line 288, in <module>
    model, history = fit(model, train_generator, test_generator, initial_epoch, final_epoch, dst_pth, num_workers, max_queue_size, initial_lr, factor, patience, min_lr)
  File "train_dct.py", line 250, in fit
    history = model.fit(x=train_generator,
  File "/home/yandex/anaconda3/envs/cntr/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py", line 1105, in fit
    callbacks.on_train_batch_end(end_step, logs)
  File "/home/yandex/anaconda3/envs/cntr/lib/python3.8/site-packages/tensorflow/python/keras/callbacks.py", line 454, in on_train_batch_end
    self._call_batch_hook(ModeKeys.TRAIN, 'end', batch, logs=logs)
  File "/home/yandex/anaconda3/envs/cntr/lib/python3.8/site-packages/tensorflow/python/keras/callbacks.py", line 296, in _call_batch_hook
    self._call_batch_end_hook(mode, batch, logs)
  File "/home/yandex/anaconda3/envs/cntr/lib/python3.8/site-packages/tensorflow/python/keras/callbacks.py", line 316, in _call_batch_end_hook
    self._call_batch_hook_helper(hook_name, batch, logs)
  File "/home/yandex/anaconda3/envs/cntr/lib/python3.8/site-packages/tensorflow/python/keras/callbacks.py", line 356, in _call_batch_hook_helper
    hook(batch, logs)
  File "/home/yandex/anaconda3/envs/cntr/lib/python3.8/site-packages/tensorflow/python/keras/callbacks.py", line 1020, in on_train_batch_end
    self._batch_update_progbar(batch, logs)
  File "/home/yandex/anaconda3/envs/cntr/lib/python3.8/site-packages/tensorflow/python/keras/callbacks.py", line 1084, in _batch_update_progbar
    logs = tf_utils.to_numpy_or_python_type(logs)
  File "/home/yandex/anaconda3/envs/cntr/lib/python3.8/site-packages/tensorflow/python/keras/utils/tf_utils.py", line 514, in to_numpy_or_python_type
    return nest.map_structure(_to_single_numpy_or_python_type, tensors)
  File "/home/yandex/anaconda3/envs/cntr/lib/python3.8/site-packages/tensorflow/python/util/nest.py", line 659, in map_structure
    structure[0], [func(*x) for x in entries],
  File "/home/yandex/anaconda3/envs/cntr/lib/python3.8/site-packages/tensorflow/python/util/nest.py", line 659, in <listcomp>
    structure[0], [func(*x) for x in entries],
  File "/home/yandex/anaconda3/envs/cntr/lib/python3.8/site-packages/tensorflow/python/keras/utils/tf_utils.py", line 510, in _to_single_numpy_or_python_type
    x = t.numpy()
  File "/home/yandex/anaconda3/envs/cntr/lib/python3.8/site-packages/tensorflow/python/framework/ops.py", line 1071, in numpy
    maybe_arr = self._numpy()  # pylint: disable=protected-access
  File "/home/yandex/anaconda3/envs/cntr/lib/python3.8/site-packages/tensorflow/python/framework/ops.py", line 1037, in _numpy
    return self._numpy_internal()
KeyboardInterrupt
