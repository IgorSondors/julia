2022-12-12 16:24:06.581480: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2022-12-12 16:24:07.741683: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2022-12-12 16:24:07.742585: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1
2022-12-12 16:24:07.906669: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:8b:00.0 name: Tesla T4 computeCapability: 7.5
coreClock: 1.59GHz coreCount: 40 deviceMemorySize: 14.56GiB deviceMemoryBandwidth: 298.08GiB/s
2022-12-12 16:24:07.906722: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2022-12-12 16:24:07.908637: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2022-12-12 16:24:07.908712: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2022-12-12 16:24:07.910402: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2022-12-12 16:24:07.910737: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2022-12-12 16:24:07.912655: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2022-12-12 16:24:07.913597: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2022-12-12 16:24:07.917487: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2022-12-12 16:24:07.922776: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2022-12-12 16:24:07.922889: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2022-12-12 16:24:07.958342: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2022-12-12 16:24:07.961046: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2022-12-12 16:24:07.964004: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:8b:00.0 name: Tesla T4 computeCapability: 7.5
coreClock: 1.59GHz coreCount: 40 deviceMemorySize: 14.56GiB deviceMemoryBandwidth: 298.08GiB/s
2022-12-12 16:24:07.964044: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2022-12-12 16:24:07.964087: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2022-12-12 16:24:07.964098: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2022-12-12 16:24:07.964107: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2022-12-12 16:24:07.964117: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2022-12-12 16:24:07.964126: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2022-12-12 16:24:07.964136: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2022-12-12 16:24:07.964146: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2022-12-12 16:24:07.969260: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2022-12-12 16:24:07.969331: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2022-12-12 16:24:08.587234: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2022-12-12 16:24:08.587288: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 
2022-12-12 16:24:08.587295: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N 
2022-12-12 16:24:08.592084: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 13784 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:8b:00.0, compute capability: 7.5)
np.shape(wn) =  (None, 128, 128, 3)
np.shape(dct) =  (None, 128, 128, 3)
np.shape(wn) =  (None, 128, 128, 3)
np.shape(fft) =  (None, 128, 128, 6)
Model: "model_2"
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            [(None, 128, 128, 3) 0                                            
__________________________________________________________________________________________________
regular_normfft3d (Lambda)      (None, 128, 128, 3)  0           input_1[0][0]                    
__________________________________________________________________________________________________
fft (Lambda)                    ((None, 128, 128, 3) 0           regular_normfft3d[0][0]          
__________________________________________________________________________________________________
regular_normdct (Lambda)        (None, 128, 128, 3)  0           input_1[0][0]                    
__________________________________________________________________________________________________
tf.cast (TFOpLambda)            (None, 128, 128, 3)  0           fft[0][0]                        
__________________________________________________________________________________________________
tf.cast_1 (TFOpLambda)          (None, 128, 128, 3)  0           fft[0][1]                        
__________________________________________________________________________________________________
dct (Lambda)                    (None, 128, 128, 3)  0           regular_normdct[0][0]            
__________________________________________________________________________________________________
tf.concat (TFOpLambda)          (None, 128, 128, 6)  0           tf.cast[0][0]                    
                                                                 tf.cast_1[0][0]                  
__________________________________________________________________________________________________
conv2d (Conv2D)                 (None, 126, 126, 32) 864         dct[0][0]                        
__________________________________________________________________________________________________
conv2d_1 (Conv2D)               (None, 126, 126, 32) 1728        tf.concat[0][0]                  
__________________________________________________________________________________________________
batch_normalization (BatchNorma (None, 126, 126, 32) 128         conv2d[0][0]                     
__________________________________________________________________________________________________
batch_normalization_4 (BatchNor (None, 126, 126, 32) 128         conv2d_1[0][0]                   
__________________________________________________________________________________________________
activation (Activation)         (None, 126, 126, 32) 0           batch_normalization[0][0]        
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 126, 126, 32) 0           batch_normalization_4[0][0]      
__________________________________________________________________________________________________
average_pooling2d (AveragePooli (None, 63, 63, 32)   0           activation[0][0]                 
__________________________________________________________________________________________________
average_pooling2d_3 (AveragePoo (None, 63, 63, 32)   0           activation_4[0][0]               
__________________________________________________________________________________________________
global_average_pooling2d (Globa (None, 32)           0           average_pooling2d[0][0]          
__________________________________________________________________________________________________
global_average_pooling2d_5 (Glo (None, 32)           0           average_pooling2d_3[0][0]        
__________________________________________________________________________________________________
dense (Dense)                   (None, 16)           528         global_average_pooling2d[0][0]   
__________________________________________________________________________________________________
dense_11 (Dense)                (None, 16)           528         global_average_pooling2d_5[0][0] 
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 32)           544         dense[0][0]                      
__________________________________________________________________________________________________
dense_12 (Dense)                (None, 32)           544         dense_11[0][0]                   
__________________________________________________________________________________________________
multiply (Multiply)             (None, 63, 63, 32)   0           dense_1[0][0]                    
                                                                 average_pooling2d[0][0]          
__________________________________________________________________________________________________
multiply_5 (Multiply)           (None, 63, 63, 32)   0           dense_12[0][0]                   
                                                                 average_pooling2d_3[0][0]        
__________________________________________________________________________________________________
conv2_dct (Conv2D)              (None, 61, 61, 32)   9248        multiply[0][0]                   
__________________________________________________________________________________________________
conv2_fft3d (Conv2D)            (None, 61, 61, 32)   9248        multiply_5[0][0]                 
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 61, 61, 32)   128         conv2_dct[0][0]                  
__________________________________________________________________________________________________
batch_normalization_5 (BatchNor (None, 61, 61, 32)   128         conv2_fft3d[0][0]                
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 61, 61, 32)   0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 61, 61, 32)   0           batch_normalization_5[0][0]      
__________________________________________________________________________________________________
average_pooling2d_1 (AveragePoo (None, 30, 30, 32)   0           activation_1[0][0]               
__________________________________________________________________________________________________
average_pooling2d_4 (AveragePoo (None, 30, 30, 32)   0           activation_5[0][0]               
__________________________________________________________________________________________________
global_average_pooling2d_1 (Glo (None, 32)           0           average_pooling2d_1[0][0]        
__________________________________________________________________________________________________
global_average_pooling2d_6 (Glo (None, 32)           0           average_pooling2d_4[0][0]        
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 16)           528         global_average_pooling2d_1[0][0] 
__________________________________________________________________________________________________
dense_13 (Dense)                (None, 16)           528         global_average_pooling2d_6[0][0] 
__________________________________________________________________________________________________
dense_3 (Dense)                 (None, 32)           544         dense_2[0][0]                    
__________________________________________________________________________________________________
dense_14 (Dense)                (None, 32)           544         dense_13[0][0]                   
__________________________________________________________________________________________________
multiply_1 (Multiply)           (None, 30, 30, 32)   0           dense_3[0][0]                    
                                                                 average_pooling2d_1[0][0]        
__________________________________________________________________________________________________
multiply_6 (Multiply)           (None, 30, 30, 32)   0           dense_14[0][0]                   
                                                                 average_pooling2d_4[0][0]        
__________________________________________________________________________________________________
conv3_dct (Conv2D)              (None, 28, 28, 32)   9248        multiply_1[0][0]                 
__________________________________________________________________________________________________
conv3_fft3d (Conv2D)            (None, 28, 28, 32)   9248        multiply_6[0][0]                 
__________________________________________________________________________________________________
batch_normalization_2 (BatchNor (None, 28, 28, 32)   128         conv3_dct[0][0]                  
__________________________________________________________________________________________________
batch_normalization_6 (BatchNor (None, 28, 28, 32)   128         conv3_fft3d[0][0]                
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 28, 28, 32)   0           batch_normalization_2[0][0]      
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 28, 28, 32)   0           batch_normalization_6[0][0]      
__________________________________________________________________________________________________
average_pooling2d_2 (AveragePoo (None, 14, 14, 32)   0           activation_2[0][0]               
__________________________________________________________________________________________________
average_pooling2d_5 (AveragePoo (None, 14, 14, 32)   0           activation_6[0][0]               
__________________________________________________________________________________________________
global_average_pooling2d_2 (Glo (None, 32)           0           average_pooling2d_2[0][0]        
__________________________________________________________________________________________________
global_average_pooling2d_7 (Glo (None, 32)           0           average_pooling2d_5[0][0]        
__________________________________________________________________________________________________
dense_4 (Dense)                 (None, 16)           528         global_average_pooling2d_2[0][0] 
__________________________________________________________________________________________________
dense_15 (Dense)                (None, 16)           528         global_average_pooling2d_7[0][0] 
__________________________________________________________________________________________________
dense_5 (Dense)                 (None, 32)           544         dense_4[0][0]                    
__________________________________________________________________________________________________
dense_16 (Dense)                (None, 32)           544         dense_15[0][0]                   
__________________________________________________________________________________________________
multiply_2 (Multiply)           (None, 14, 14, 32)   0           dense_5[0][0]                    
                                                                 average_pooling2d_2[0][0]        
__________________________________________________________________________________________________
multiply_7 (Multiply)           (None, 14, 14, 32)   0           dense_16[0][0]                   
                                                                 average_pooling2d_5[0][0]        
__________________________________________________________________________________________________
conv4_dct (Conv2D)              (None, 12, 12, 32)   9216        multiply_2[0][0]                 
__________________________________________________________________________________________________
conv4_fft3d (Conv2D)            (None, 12, 12, 32)   9216        multiply_7[0][0]                 
__________________________________________________________________________________________________
batch_normalization_3 (BatchNor (None, 12, 12, 32)   128         conv4_dct[0][0]                  
__________________________________________________________________________________________________
batch_normalization_7 (BatchNor (None, 12, 12, 32)   128         conv4_fft3d[0][0]                
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 12, 12, 32)   0           batch_normalization_3[0][0]      
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 12, 12, 32)   0           batch_normalization_7[0][0]      
__________________________________________________________________________________________________
global_average_pooling2d_3 (Glo (None, 32)           0           activation_3[0][0]               
__________________________________________________________________________________________________
global_average_pooling2d_8 (Glo (None, 32)           0           activation_7[0][0]               
__________________________________________________________________________________________________
dense_6 (Dense)                 (None, 16)           528         global_average_pooling2d_3[0][0] 
__________________________________________________________________________________________________
dense_17 (Dense)                (None, 16)           528         global_average_pooling2d_8[0][0] 
__________________________________________________________________________________________________
dense_7 (Dense)                 (None, 32)           544         dense_6[0][0]                    
__________________________________________________________________________________________________
dense_18 (Dense)                (None, 32)           544         dense_17[0][0]                   
__________________________________________________________________________________________________
multiply_3 (Multiply)           (None, 12, 12, 32)   0           dense_7[0][0]                    
                                                                 activation_3[0][0]               
__________________________________________________________________________________________________
multiply_8 (Multiply)           (None, 12, 12, 32)   0           dense_18[0][0]                   
                                                                 activation_7[0][0]               
__________________________________________________________________________________________________
conv5_dct (Conv2D)              (None, 12, 12, 32)   1056        multiply_3[0][0]                 
__________________________________________________________________________________________________
conv5_fft3d (Conv2D)            (None, 12, 12, 32)   1056        multiply_8[0][0]                 
__________________________________________________________________________________________________
global_average_pooling2d_4 (Glo (None, 32)           0           conv5_dct[0][0]                  
__________________________________________________________________________________________________
global_average_pooling2d_9 (Glo (None, 32)           0           conv5_fft3d[0][0]                
__________________________________________________________________________________________________
dense_8 (Dense)                 (None, 16)           528         global_average_pooling2d_4[0][0] 
__________________________________________________________________________________________________
dense_19 (Dense)                (None, 16)           528         global_average_pooling2d_9[0][0] 
WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.
2022-12-12 16:24:50.184477: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)
2022-12-12 16:24:50.184886: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 1995310000 Hz
2022-12-12 16:24:54.955146: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2022-12-12 16:24:55.999108: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2022-12-12 16:24:56.270793: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2022-12-12 16:24:57.337654: W tensorflow/stream_executor/gpu/asm_compiler.cc:63] Running ptxas --version returned 256
2022-12-12 16:24:57.501344: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] Internal: ptxas exited with non-zero error code 256, output: 
Relying on driver to perform ptx compilation. 
Modify $PATH to customize ptxas location.
This message will be only logged once.
__________________________________________________________________________________________________
dense_9 (Dense)                 (None, 32)           544         dense_8[0][0]                    
__________________________________________________________________________________________________
dense_20 (Dense)                (None, 32)           544         dense_19[0][0]                   
__________________________________________________________________________________________________
multiply_4 (Multiply)           (None, 12, 12, 32)   0           dense_9[0][0]                    
                                                                 conv5_dct[0][0]                  
__________________________________________________________________________________________________
multiply_9 (Multiply)           (None, 12, 12, 32)   0           dense_20[0][0]                   
                                                                 conv5_fft3d[0][0]                
__________________________________________________________________________________________________
flatten (Flatten)               (None, 4608)         0           multiply_4[0][0]                 
__________________________________________________________________________________________________
flatten_1 (Flatten)             (None, 4608)         0           multiply_9[0][0]                 
__________________________________________________________________________________________________
dropout (Dropout)               (None, 4608)         0           flatten[0][0]                    
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 4608)         0           flatten_1[0][0]                  
__________________________________________________________________________________________________
dense_10 (Dense)                (None, 32)           147488      dropout[0][0]                    
__________________________________________________________________________________________________
dense_21 (Dense)                (None, 32)           147488      dropout_1[0][0]                  
__________________________________________________________________________________________________
concatenate (Concatenate)       (None, 64)           0           dense_10[0][0]                   
                                                                 dense_21[0][0]                   
__________________________________________________________________________________________________
dense_22 (Dense)                (None, 12)           780         concatenate[0][0]                
__________________________________________________________________________________________________
dense_23 (Dense)                (None, 1)            13          dense_22[0][0]                   
==================================================================================================
Total params: 367,641
Trainable params: 367,129
Non-trainable params: 512
__________________________________________________________________________________________________
None
                                                    file spoof
0      /mnt/data/lossless_val_04102022_crops/1/chrome...     1
1      /mnt/data/lossless_val_04102022_crops/1/2d7db3...     1
2      /mnt/data/lossless_val_04102022_crops/1/chroma...     1
3      /mnt/data/lossless_val_04102022_crops/0/c86649...     0
4      /mnt/data/lossless_val_04102022_crops/1/chrome...     1
...                                                  ...   ...
40073  /mnt/data/lossless_val_04102022_crops/1/chrome...     1
40074  /mnt/data/lossless_val_04102022_crops/0/5c2b86...     0
40075  /mnt/data/lossless_val_04102022_crops/0/5c79a2...     0
40076  /mnt/data/lossless_val_04102022_crops/1/firefo...     1
40077  /mnt/data/lossless_val_04102022_crops/1/63559a...     1

[40078 rows x 2 columns]
train_cls_n =  [2785410, 2859310] 2
test_cls_n =  [19998, 20080] 2
Found 5644720 validated image filenames belonging to 2 classes.
Found 40078 validated image filenames belonging to 2 classes.
Epoch 1/7
    1/11289 [..............................] - ETA: 74:55:19 - loss: 0.6934 - accuracy: 0.5240    2/11289 [..............................] - ETA: 2:22:55 - loss: 0.7107 - accuracy: 0.5240     3/11289 [..............................] - ETA: 2:08:27 - loss: 0.7134 - accuracy: 0.5276    4/11289 [..............................] - ETA: 2:03:43 - loss: 0.7116 - accuracy: 0.5383    5/11289 [..............................] - ETA: 2:01:26 - loss: 0.7083 - accuracy: 0.5467    6/11289 [..............................] - ETA: 2:00:02 - loss: 0.7045 - accuracy: 0.5545    7/11289 [..............................] - ETA: 1:59:09 - loss: 0.7006 - accuracy: 0.5617    8/11289 [..............................] - ETA: 1:58:25 - loss: 0.6959 - accuracy: 0.5687    9/11289 [..............................] - ETA: 1:57:43 - loss: 0.6918 - accuracy: 0.5751   10/11289 [..............................] - ETA: 1:57:19 - loss: 0.6883 - accuracy: 0.5800   11/11289 [..............................] - ETA: 1:57:10 - loss: 0.6851 - accuracy: 0.5844   12/11289 [..............................] - ETA: 1:56:56 - loss: 0.6819 - accuracy: 0.5887   13/11289 [..............................] - ETA: 1:56:44 - loss: 0.6786 - accuracy: 0.5931   14/11289 [..............................] - ETA: 1:56:31 - loss: 0.6754 - accuracy: 0.5973   15/11289 [..............................] - ETA: 1:56:22 - loss: 0.6724 - accuracy: 0.6013   16/11289 [..............................] - ETA: 1:56:12 - loss: 0.6695 - accuracy: 0.6051   17/11289 [..............................] - ETA: 1:56:05 - loss: 0.6667 - accuracy: 0.6087   18/11289 [..............................] - ETA: 1:55:58 - loss: 0.6639 - accuracy: 0.6122   19/11289 [..............................] - ETA: 1:55:53 - loss: 0.6612 - accuracy: 0.6154   20/11289 [..............................] - ETA: 1:55:44 - loss: 0.6588 - accuracy: 0.6185   21/11289 [..............................] - ETA: 1:55:39 - loss: 0.6565 - accuracy: 0.6215   22/11289 [..............................] - ETA: 1:55:35 - loss: 0.6541 - accuracy: 0.6244   23/11289 [..............................] - ETA: 1:55:33 - loss: 0.6517 - accuracy: 0.6272   24/11289 [..............................] - ETA: 1:55:30 - loss: 0.6495 - accuracy: 0.6300   25/11289 [..............................] - ETA: 1:55:28 - loss: 0.6473 - accuracy: 0.6326   26/11289 [..............................] - ETA: 1:55:26 - loss: 0.6452 - accuracy: 0.6350   27/11289 [..............................] - ETA: 1:55:23 - loss: 0.6431 - accuracy: 0.6373   28/11289 [..............................] - ETA: 1:55:21 - loss: 0.6410 - accuracy: 0.6396   29/11289 [..............................] - ETA: 1:55:19 - loss: 0.6391 - accuracy: 0.6418   30/11289 [..............................] - ETA: 1:55:16 - loss: 0.6372 - accuracy: 0.6438   31/11289 [..............................] - ETA: 1:55:13 - loss: 0.6355 - accuracy: 0.6456   32/11289 [..............................] - ETA: 1:55:08 - loss: 0.6338 - accuracy: 0.6474   33/11289 [..............................] - ETA: 1:55:06 - loss: 0.6322 - accuracy: 0.6492   34/11289 [..............................] - ETA: 1:55:11 - loss: 0.6305 - accuracy: 0.6510   35/11289 [..............................] - ETA: 1:55:09 - loss: 0.6289 - accuracy: 0.6526   36/11289 [..............................] - ETA: 1:55:10 - loss: 0.6273 - accuracy: 0.6542   37/11289 [..............................] - ETA: 1:55:10 - loss: 0.6258 - accuracy: 0.6558   38/11289 [..............................] - ETA: 1:55:06 - loss: 0.6242 - accuracy: 0.6573   39/11289 [..............................] - ETA: 1:55:04 - loss: 0.6227 - accuracy: 0.6588   40/11289 [..............................] - ETA: 1:55:02 - loss: 0.6213 - accuracy: 0.6602   41/11289 [..............................] - ETA: 1:55:00 - loss: 0.6199 - accuracy: 0.6616   42/11289 [..............................] - ETA: 1:54:59 - loss: 0.6185 - accuracy: 0.6629   43/11289 [..............................] - ETA: 1:54:57 - loss: 0.6172 - accuracy: 0.6643   44/11289 [..............................] - ETA: 1:54:56 - loss: 0.6159 - accuracy: 0.6655   45/11289 [..............................] - ETA: 1:54:55 - loss: 0.6146 - accuracy: 0.6668   46/11289 [..............................] - ETA: 1:54:54 - loss: 0.6134 - accuracy: 0.6680   47/11289 [..............................] - ETA: 1:54:54 - loss: 0.6122 - accuracy: 0.6692   48/11289 [..............................] - ETA: 1:54:53 - loss: 0.6110 - accuracy: 0.6703   49/11289 [..............................] - ETA: 1:54:51 - loss: 0.6098 - accuracy: 0.6715   50/11289 [..............................] - ETA: 1:54:49 - loss: 0.6087 - accuracy: 0.6726   51/11289 [..............................] - ETA: 1:54:48 - loss: 0.6075 - accuracy: 0.6737   52/11289 [..............................] - ETA: 1:54:47 - loss: 0.6064 - accuracy: 0.6748   53/11289 [..............................] - ETA: 1:54:46 - loss: 0.6053 - accuracy: 0.6758   54/11289 [..............................] - ETA: 1:54:45 - loss: 0.6041 - accuracy: 0.6769   55/11289 [..............................] - ETA: 1:54:51 - loss: 0.6030 - accuracy: 0.6779   56/11289 [..............................] - ETA: 1:54:50 - loss: 0.6019 - accuracy: 0.6790   57/11289 [..............................] - ETA: 1:54:49 - loss: 0.6008 - accuracy: 0.6800   58/11289 [..............................] - ETA: 1:54:47 - loss: 0.5997 - accuracy: 0.6810   59/11289 [..............................] - ETA: 1:54:46 - loss: 0.5987 - accuracy: 0.6819   60/11289 [..............................] - ETA: 1:54:45 - loss: 0.5976 - accuracy: 0.6829   61/11289 [..............................] - ETA: 1:54:43 - loss: 0.5965 - accuracy: 0.6839   62/11289 [..............................] - ETA: 1:54:43 - loss: 0.5955 - accuracy: 0.6848   63/11289 [..............................] - ETA: 1:54:43 - loss: 0.5945 - accuracy: 0.6857   64/11289 [..............................] - ETA: 1:54:42 - loss: 0.5935 - accuracy: 0.6866   65/11289 [..............................] - ETA: 1:54:41 - loss: 0.5925 - accuracy: 0.6875   66/11289 [..............................] - ETA: 1:54:40 - loss: 0.5915 - accuracy: 0.6884   67/11289 [..............................] - ETA: 1:54:39 - loss: 0.5905 - accuracy: 0.6892   68/11289 [..............................] - ETA: 1:54:38 - loss: 0.5895 - accuracy: 0.6901   69/11289 [..............................] - ETA: 1:54:39 - loss: 0.5886 - accuracy: 0.6909   70/11289 [..............................] - ETA: 1:54:37 - loss: 0.5876 - accuracy: 0.6917   71/11289 [..............................] - ETA: 1:54:37 - loss: 0.5867 - accuracy: 0.6925   72/11289 [..............................] - ETA: 1:54:36 - loss: 0.5858 - accuracy: 0.6933   73/11289 [..............................] - ETA: 1:54:36 - loss: 0.5849 - accuracy: 0.6941   74/11289 [..............................] - ETA: 1:54:36 - loss: 0.5840 - accuracy: 0.6949   75/11289 [..............................] - ETA: 1:54:35 - loss: 0.5831 - accuracy: 0.6956   76/11289 [..............................] - ETA: 1:54:35 - loss: 0.5823 - accuracy: 0.6964   77/11289 [..............................] - ETA: 1:54:35 - loss: 0.5814 - accuracy: 0.6971   78/11289 [..............................] - ETA: 1:54:35 - loss: 0.5805 - accuracy: 0.6979   79/11289 [..............................] - ETA: 1:54:35 - loss: 0.5797 - accuracy: 0.6986   80/11289 [..............................] - ETA: 1:54:35 - loss: 0.5788 - accuracy: 0.6993   81/11289 [..............................] - ETA: 1:54:35 - loss: 0.5780 - accuracy: 0.7000   82/11289 [..............................] - ETA: 1:54:35 - loss: 0.5772 - accuracy: 0.7007   83/11289 [..............................] - ETA: 1:54:35 - loss: 0.5764 - accuracy: 0.7014   84/11289 [..............................] - ETA: 1:54:35 - loss: 0.5756 - accuracy: 0.7021   85/11289 [..............................] - ETA: 1:54:33 - loss: 0.5748 - accuracy: 0.7028   86/11289 [..............................] - ETA: 1:54:32 - loss: 0.5740 - accuracy: 0.7034   87/11289 [..............................] - ETA: 1:54:31 - loss: 0.5732 - accuracy: 0.7041   88/11289 [..............................] - ETA: 1:54:31 - loss: 0.5724 - accuracy: 0.7047   89/11289 [..............................] - ETA: 1:54:31 - loss: 0.5717 - accuracy: 0.7053   90/11289 [..............................] - ETA: 1:54:30 - loss: 0.5709 - accuracy: 0.7060   91/11289 [..............................] - ETA: 1:54:29 - loss: 0.5702 - accuracy: 0.7066   92/11289 [..............................] - ETA: 1:54:28 - loss: 0.5694 - accuracy: 0.7072   93/11289 [..............................] - ETA: 1:54:27 - loss: 0.5687 - accuracy: 0.7078   94/11289 [..............................] - ETA: 1:54:27 - loss: 0.5679 - accuracy: 0.7084   95/11289 [..............................] - ETA: 1:54:26 - loss: 0.5672 - accuracy: 0.7090   96/11289 [..............................] - ETA: 1:54:25 - loss: 0.5665 - accuracy: 0.7096   97/11289 [..............................] - ETA: 1:54:25 - loss: 0.5658 - accuracy: 0.7102   98/11289 [..............................] - ETA: 1:54:25 - loss: 0.5651 - accuracy: 0.7107   99/11289 [..............................] - ETA: 1:54:25 - loss: 0.5644 - accuracy: 0.7113  100/11289 [..............................] - ETA: 1:54:25 - loss: 0.5637 - accuracy: 0.7118  101/11289 [..............................] - ETA: 1:54:24 - loss: 0.5631 - accuracy: 0.7124  102/11289 [..............................] - ETA: 1:54:24 - loss: 0.5624 - accuracy: 0.7129  103/11289 [..............................] - ETA: 1:54:24 - loss: 0.5617 - accuracy: 0.7135  104/11289 [..............................] - ETA: 1:54:24 - loss: 0.5611 - accuracy: 0.7140  105/11289 [..............................] - ETA: 1:54:23 - loss: 0.5604 - accuracy: 0.7146  106/11289 [..............................] - ETA: 1:54:23 - loss: 0.5597 - accuracy: 0.7151  107/11289 [..............................] - ETA: 1:54:23 - loss: 0.5591 - accuracy: 0.7156  108/11289 [..............................] - ETA: 1:54:22 - loss: 0.5585 - accuracy: 0.7161  109/11289 [..............................] - ETA: 1:54:22 - loss: 0.5578 - accuracy: 0.7166  110/11289 [..............................] - ETA: 1:54:22 - loss: 0.5572 - accuracy: 0.7171  111/11289 [..............................] - ETA: 1:54:22 - loss: 0.5566 - accuracy: 0.7176  112/11289 [..............................] - ETA: 1:54:23 - loss: 0.5560 - accuracy: 0.7181  113/11289 [..............................] - ETA: 1:54:22 - loss: 0.5554 - accuracy: 0.7186  114/11289 [..............................] - ETA: 1:54:22 - loss: 0.5547 - accuracy: 0.7190  115/11289 [..............................] - ETA: 1:54:22 - loss: 0.5541 - accuracy: 0.7195  116/11289 [..............................] - ETA: 1:54:21 - loss: 0.5536 - accuracy: 0.7200  117/11289 [..............................] - ETA: 1:54:21 - loss: 0.5530 - accuracy: 0.7204  118/11289 [..............................] - ETA: 1:54:21 - loss: 0.5524 - accuracy: 0.7209  119/11289 [..............................] - ETA: 1:54:21 - loss: 0.5518 - accuracy: 0.7214  120/11289 [..............................] - ETA: 1:54:20 - loss: 0.5512 - accuracy: 0.7218  121/11289 [..............................] - ETA: 1:54:20 - loss: 0.5506 - accuracy: 0.7223  122/11289 [..............................] - ETA: 1:54:20 - loss: 0.5501 - accuracy: 0.7227  123/11289 [..............................] - ETA: 1:54:20 - loss: 0.5495 - accuracy: 0.7231  124/11289 [..............................] - ETA: 1:54:19 - loss: 0.5489 - accuracy: 0.7236  125/11289 [..............................] - ETA: 1:54:19 - loss: 0.5484 - accuracy: 0.7240  126/11289 [..............................] - ETA: 1:54:19 - loss: 0.5478 - accuracy: 0.7244  127/11289 [..............................] - ETA: 1:54:19 - loss: 0.5473 - accuracy: 0.7249  128/11289 [..............................] - ETA: 1:54:18 - loss: 0.5467 - accuracy: 0.7253  129/11289 [..............................] - ETA: 1:54:19 - loss: 0.5462 - accuracy: 0.7257  130/11289 [..............................] - ETA: 1:54:19 - loss: 0.5457 - accuracy: 0.7261  131/11289 [..............................] - ETA: 1:54:19 - loss: 0.5451 - accuracy: 0.7265  132/11289 [..............................] - ETA: 1:54:19 - loss: 0.5446 - accuracy: 0.7269  133/11289 [..............................] - ETA: 1:54:18 - loss: 0.5441 - accuracy: 0.7273  134/11289 [..............................] - ETA: 1:54:18 - loss: 0.5436 - accuracy: 0.7277  135/11289 [..............................] - ETA: 1:54:17 - loss: 0.5430 - accuracy: 0.7281  136/11289 [..............................] - ETA: 1:54:17 - loss: 0.5425 - accuracy: 0.7285  137/11289 [..............................] - ETA: 1:54:16 - loss: 0.5420 - accuracy: 0.7289  138/11289 [..............................] - ETA: 1:54:16 - loss: 0.5415 - accuracy: 0.7293  139/11289 [..............................] - ETA: 1:54:15 - loss: 0.5410 - accuracy: 0.7297  140/11289 [..............................] - ETA: 1:54:15 - loss: 0.5405 - accuracy: 0.7301  141/11289 [..............................] - ETA: 1:54:15 - loss: 0.5400 - accuracy: 0.7304  142/11289 [..............................] - ETA: 1:54:15 - loss: 0.5395 - accuracy: 0.7308  143/11289 [..............................] - ETA: 1:54:14 - loss: 0.5390 - accuracy: 0.7312  144/11289 [..............................] - ETA: 1:54:16 - loss: 0.5385 - accuracy: 0.7316  145/11289 [..............................] - ETA: 1:54:16 - loss: 0.5380 - accuracy: 0.7319  146/11289 [..............................] - ETA: 1:54:16 - loss: 0.5376 - accuracy: 0.7323  147/11289 [..............................] - ETA: 1:54:15 - loss: 0.5371 - accuracy: 0.7326  148/11289 [..............................] - ETA: 1:54:15 - loss: 0.5366 - accuracy: 0.7330  149/11289 [..............................] - ETA: 1:54:14 - loss: 0.5361 - accuracy: 0.7334  150/11289 [..............................] - ETA: 1:54:14 - loss: 0.5357 - accuracy: 0.7337  151/11289 [..............................] - ETA: 1:54:14 - loss: 0.5352 - accuracy: 0.7341  152/11289 [..............................] - ETA: 1:54:13 - loss: 0.5347 - accuracy: 0.7344  153/11289 [..............................] - ETA: 1:54:13 - loss: 0.5343 - accuracy: 0.7347  154/11289 [..............................] - ETA: 1:54:13 - loss: 0.5338 - accuracy: 0.7351Traceback (most recent call last):
  File "train_dct.py", line 288, in <module>
    model, history = fit(model, train_generator, test_generator, initial_epoch, final_epoch, dst_pth, num_workers, max_queue_size, initial_lr, factor, patience, min_lr)
  File "train_dct.py", line 250, in fit
    history = model.fit(x=train_generator,
  File "/home/yandex/anaconda3/envs/cntr/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py", line 1100, in fit
    tmp_logs = self.train_function(iterator)
  File "/home/yandex/anaconda3/envs/cntr/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py", line 828, in __call__
    result = self._call(*args, **kwds)
  File "/home/yandex/anaconda3/envs/cntr/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py", line 855, in _call
    return self._stateless_fn(*args, **kwds)  # pylint: disable=not-callable
  File "/home/yandex/anaconda3/envs/cntr/lib/python3.8/site-packages/tensorflow/python/eager/function.py", line 2942, in __call__
    return graph_function._call_flat(
  File "/home/yandex/anaconda3/envs/cntr/lib/python3.8/site-packages/tensorflow/python/eager/function.py", line 1918, in _call_flat
    return self._build_call_outputs(self._inference_function.call(
  File "/home/yandex/anaconda3/envs/cntr/lib/python3.8/site-packages/tensorflow/python/eager/function.py", line 555, in call
    outputs = execute.execute(
  File "/home/yandex/anaconda3/envs/cntr/lib/python3.8/site-packages/tensorflow/python/eager/execute.py", line 59, in quick_execute
    tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,
KeyboardInterrupt
2022-12-12 16:26:49.310753: W tensorflow/core/kernels/data/generator_dataset_op.cc:107] Error occurred when finalizing GeneratorDataset iterator: Failed precondition: Python interpreter state is not initialized. The process may be terminated.
	 [[{{node PyFunc}}]]
